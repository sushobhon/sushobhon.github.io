<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sushobhon Karmakar">
<meta name="dcterms.date" content="2025-08-10">
<meta name="description" content="Full Finetunning a LLM Model">

<title>Bet: Full Fine-Tuning Your Own LLM (A Handas-on Guide) – Sushobhon Karmakar</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2fa0555fe88427c29efa1b60aaf9e62d.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-6d7e7b9b3dbd114c66b233ded7072392.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-7e11434eac148b84e24ebc123ea223a9.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-caa6200b5fd6ae1557848632e0b2b910.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/quarto-contrib/fontawesome6-1.2.0/all.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-1.2.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Sushobhon Karmakar</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../project.html"> 
<span class="menu-text">Project</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../skills.html"> 
<span class="menu-text">Skills</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blogs.html"> 
<span class="menu-text">Blogs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../Resume"> 
<span class="menu-text">resume.qmd</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="mailto:sushobhonkarmakar@gmail.com"> 
<span class="menu-text"><i class="fa-solid fa-envelope fa-large" aria-label="envelope"></i></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.linkedin.com/in/sushobhon-karmakar-579403160/"> 
<span class="menu-text"><i class="fa-brands fa-linkedin-in fa-large" aria-label="linkedin-in"></i></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://x.com/sushobhon96"> 
<span class="menu-text"><i class="fa-brands fa-x-twitter fa-large" aria-label="x-twitter"></i></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/sushobhon"> 
<span class="menu-text"><i class="fa-brands fa-github fa-large" aria-label="github"></i></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Bet: Full Fine-Tuning Your Own LLM (A Handas-on Guide)</h1>
                  <div>
        <div class="description">
          Full Finetunning a LLM Model
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">LLM</div>
                <div class="quarto-category">Gen AI</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Sushobhon Karmakar </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 10, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#importing-necessary-libraries-and-dataset" id="toc-importing-necessary-libraries-and-dataset" class="nav-link active" data-scroll-target="#importing-necessary-libraries-and-dataset">Importing Necessary Libraries and Dataset</a></li>
  <li><a href="#processing-and-splitting" id="toc-processing-and-splitting" class="nav-link" data-scroll-target="#processing-and-splitting">Processing and Splitting</a></li>
  <li><a href="#loading-pre-trained-llm-model" id="toc-loading-pre-trained-llm-model" class="nav-link" data-scroll-target="#loading-pre-trained-llm-model">Loading Pre-Trained LLM Model</a></li>
  <li><a href="#tokenizing" id="toc-tokenizing" class="nav-link" data-scroll-target="#tokenizing">Tokenizing</a></li>
  <li><a href="#training-model" id="toc-training-model" class="nav-link" data-scroll-target="#training-model">Training Model</a></li>
  <li><a href="#evaluating-the-model" id="toc-evaluating-the-model" class="nav-link" data-scroll-target="#evaluating-the-model">Evaluating The Model</a></li>
  <li><a href="#testing" id="toc-testing" class="nav-link" data-scroll-target="#testing">Testing</a></li>
  <li><a href="#pros" id="toc-pros" class="nav-link" data-scroll-target="#pros">Pros</a></li>
  <li><a href="#cons" id="toc-cons" class="nav-link" data-scroll-target="#cons">Cons</a></li>
  <li><a href="#alternatives" id="toc-alternatives" class="nav-link" data-scroll-target="#alternatives">Alternatives</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>Large Language Models (<strong>LLM</strong>s) have demonstrated remarkable capabilities in understanding and generating human-like text across a vast range of topics. However, to make these powerful models perform exceptionally well on a specific task or within a particular domain, a crucial step is often required: <strong>fine-tuning</strong>.</p>
<p>Fine-tuning is the process of taking a pre-trained LLM – a model that has already learned a broad understanding of language from massive datasets – and training it further on a smaller, task-specific dataset. This allows the model to adapt its existing knowledge and become highly proficient at the new task.</p>
<p>In this blog post, we will delve into one of the most comprehensive and basic fine-tuning approaches: <strong>full fine-tuning</strong>. This method involves updating <em>all</em> the parameters (or weights) of the pre-trained model based on the new, task-specific data. While computationally more intensive than some other methods, it can yield significant performance improvements for specialized tasks.</p>
<p>As a practical example, we will walk through the process of full fine-tuning the <code>distilgpt2</code> model using a dataset designed for translating standard English sentences into the unique syntax of Yoda from <em>Star Wars</em>. By the end of this hands-on guide, you will see how fine-tuning can fundamentally change a model’s output to perform a fun, yet illustrative, language transformation task.</p>
<p>Join us as we explore the steps involved in full fine-tuning and transform a general-purpose model into a Yoda-speak expert.</p>
<p>Before we star we need to install <code>torch</code> , <code>transformers</code> , <code>datasets</code> and <code>accelerator</code> packages</p>
<section id="importing-necessary-libraries-and-dataset" class="level2">
<h2 class="anchored" data-anchor-id="importing-necessary-libraries-and-dataset">Importing Necessary Libraries and Dataset</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset, DatasetDict</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">from</span> transformers <span class="im">import</span> (</span>
<span id="cb1-4"><a href="#cb1-4"></a>    AutoTokenizer,</span>
<span id="cb1-5"><a href="#cb1-5"></a>    AutoModelForCausalLM,</span>
<span id="cb1-6"><a href="#cb1-6"></a>    TrainingArguments,</span>
<span id="cb1-7"><a href="#cb1-7"></a>    Trainer,</span>
<span id="cb1-8"><a href="#cb1-8"></a>    DataCollatorForLanguageModeling</span>
<span id="cb1-9"><a href="#cb1-9"></a>)</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="im">import</span> math</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We have used <a href="https://huggingface.co/datasets/dvgodoy/yoda_sentences">yoda_sentences</a> dataset prepared by <strong><a href="https://huggingface.co/dvgodoy">Daniel Voigt Godoy</a></strong>. This Dataset is available in huggingface.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># Step 1: Load the dataset.</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>dataset <span class="op">=</span> load_dataset(<span class="st">"dvgodoy/yoda_sentences"</span>)</span>
<span id="cb2-3"><a href="#cb2-3"></a></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="co"># Viewing the dataset</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>dataset[<span class="st">'train'</span>][:<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This is a snap short of the datset. We have 3 Columns - <code>sentence</code> (Actual English Sentence), <code>translation</code> (Yoda Translation of the actuall sentence) and <code>translation_extra</code> (Yoda Translation with few extra words).</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>{<span class="st">'sentence'</span>: [<span class="st">'The birch canoe slid on the smooth planks.'</span>,</span>
<span id="cb3-2"><a href="#cb3-2"></a>  <span class="st">'Glue the sheet to the dark blue background.'</span>],</span>
<span id="cb3-3"><a href="#cb3-3"></a> <span class="st">'translation'</span>: [<span class="st">'On the smooth planks, the birch canoe slid.'</span>,</span>
<span id="cb3-4"><a href="#cb3-4"></a>  <span class="st">'Glue the sheet to the dark blue background, you must.'</span>],</span>
<span id="cb3-5"><a href="#cb3-5"></a> <span class="st">'translation_extra'</span>: [<span class="st">'On the smooth planks, the birch canoe slid. Yes, hrrrm.'</span>,</span>
<span id="cb3-6"><a href="#cb3-6"></a>  <span class="st">'Glue the sheet to the dark blue background, you must.'</span>]}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="processing-and-splitting" class="level2">
<h2 class="anchored" data-anchor-id="processing-and-splitting">Processing and Splitting</h2>
<p>We can’t directly use this dataset to fine-tune our large language model (LLM) because LLMs are designed to predict the next word (or token) in a sequence of text. That means we need to convert our structured tabular data into plain text in a way the model can understand.</p>
<p>To do this, we’ll format each row of data into a readable sentence like:</p>
<p><code>“Sentence: [Actual English Sentence] Translation: [Translated Text]”</code></p>
<p>This gives the model context it can learn from.</p>
<p>Let’s write a function to handle this transformation:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="kw">def</span> format_yoda(example):</span>
<span id="cb4-2"><a href="#cb4-2"></a>        <span class="co">"""Function to transform dataset from Tabular from to Text."""</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>    <span class="cf">return</span> {<span class="st">"text"</span>: <span class="ss">f"Sentence: </span><span class="sc">{</span>example[<span class="st">'sentence'</span>]<span class="sc">}</span><span class="ss"> Translation: </span><span class="sc">{</span>example[<span class="st">'translation_extra'</span>]<span class="sc">}</span><span class="ss">"</span>}</span>
<span id="cb4-4"><a href="#cb4-4"></a></span>
<span id="cb4-5"><a href="#cb4-5"></a><span class="co"># Applying function on each row of the dataset </span></span>
<span id="cb4-6"><a href="#cb4-6"></a>dataset <span class="op">=</span> dataset.<span class="bu">map</span>(format_yoda)</span>
<span id="cb4-7"><a href="#cb4-7"></a></span>
<span id="cb4-8"><a href="#cb4-8"></a><span class="co"># Dataset after transformation</span></span>
<span id="cb4-9"><a href="#cb4-9"></a>dataset[<span class="st">'train'</span>][<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a>{<span class="st">'sentence'</span>: <span class="st">'The birch canoe slid on the smooth planks.'</span>,</span>
<span id="cb5-2"><a href="#cb5-2"></a> <span class="st">'translation'</span>: <span class="st">'On the smooth planks, the birch canoe slid.'</span>,</span>
<span id="cb5-3"><a href="#cb5-3"></a> <span class="st">'translation_extra'</span>: <span class="st">'On the smooth planks, the birch canoe slid. Yes, hrrrm.'</span>,</span>
<span id="cb5-4"><a href="#cb5-4"></a> <span class="st">'text'</span>: <span class="st">'Sentence: The birch canoe slid on the smooth planks. Translation: On the smooth planks, the birch canoe slid. Yes, hrrrm.'</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>As you can see a new column <code>text</code> is created.</p>
<p>Lets us split the data into train and evaluation set to check the performance</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="co"># Splitting the dataset to train and evaluation set</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>train_eval_split <span class="op">=</span> dataset[<span class="st">"train"</span>].train_test_split(test_size<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb6-3"><a href="#cb6-3"></a>dataset <span class="op">=</span> DatasetDict({</span>
<span id="cb6-4"><a href="#cb6-4"></a>    <span class="st">'train'</span>: train_eval_split[<span class="st">'train'</span>],</span>
<span id="cb6-5"><a href="#cb6-5"></a>    <span class="st">'eval'</span>: train_eval_split[<span class="st">'test'</span>]</span>
<span id="cb6-6"><a href="#cb6-6"></a>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="loading-pre-trained-llm-model" class="level2">
<h2 class="anchored" data-anchor-id="loading-pre-trained-llm-model">Loading Pre-Trained LLM Model</h2>
<p>Now that our dataset is ready, let’s download the <strong>DistilGPT2</strong> model from HuggingFace. <em>DistilGPT2</em> is a lightweight and faster version of the original <em>GPT-2</em> model, with around 82 million parameters. It’s a great choice for fine-tuning when you’re working with limited resources or need quicker performance.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># Step 2: Load a small pre-trained LLM model and tokenizer</span></span>
<span id="cb7-2"><a href="#cb7-2"></a>model_name <span class="op">=</span> <span class="st">"distilgpt2"</span></span>
<span id="cb7-3"><a href="#cb7-3"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb7-4"><a href="#cb7-4"></a>model <span class="op">=</span> AutoModelForCausalLM.from_pretrained(model_name)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="kw">def</span> print_number_of_trainable_model_parameters(model):</span>
<span id="cb8-2"><a href="#cb8-2"></a>    <span class="co">"""Function to find out trainable and non-trainable parameters"""</span></span>
<span id="cb8-3"><a href="#cb8-3"></a>    trainable_model_params <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-4"><a href="#cb8-4"></a>    all_model_params <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-5"><a href="#cb8-5"></a>    <span class="cf">for</span> _, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb8-6"><a href="#cb8-6"></a>        all_model_params <span class="op">+=</span> param.numel()</span>
<span id="cb8-7"><a href="#cb8-7"></a>        <span class="cf">if</span> param.requires_grad:</span>
<span id="cb8-8"><a href="#cb8-8"></a>            trainable_model_params <span class="op">+=</span> param.numel()</span>
<span id="cb8-9"><a href="#cb8-9"></a>    <span class="cf">return</span> <span class="ss">f"trainable model parameters: </span><span class="sc">{</span>trainable_model_params<span class="sc">}</span><span class="ch">\n</span><span class="ss">all model parameters: </span><span class="sc">{</span>all_model_params<span class="sc">}</span><span class="ch">\n</span><span class="ss">percentage of trainable model parameters: </span><span class="sc">{</span><span class="dv">100</span> <span class="op">*</span> trainable_model_params <span class="op">/</span> all_model_params<span class="sc">:.2f}</span><span class="ss">%"</span></span>
<span id="cb8-10"><a href="#cb8-10"></a></span>
<span id="cb8-11"><a href="#cb8-11"></a><span class="bu">print</span>(print_number_of_trainable_model_parameters(model))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb9-1"><a href="#cb9-1"></a>trainable model parameters: 81912576</span>
<span id="cb9-2"><a href="#cb9-2"></a>all model parameters: 81912576</span>
<span id="cb9-3"><a href="#cb9-3"></a>percentage of trainable model parameters: 100.00%</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Since we’re fully fine-tuning the model, we’ll be updating all 82 million parameters. But before we start the fine-tuning process, let’s evaluate how the pretrained model performs out of the box.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># Let's try to translate the sentence using original model.</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>prompt <span class="op">=</span> <span class="st">"Sentence: The Sky is clear, it's time to fly.</span><span class="ch">\n</span><span class="st">Translation:"</span> </span>
<span id="cb10-3"><a href="#cb10-3"></a>input_ids <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>).input_ids.to(model.device)</span>
<span id="cb10-4"><a href="#cb10-4"></a></span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="co"># Generate text</span></span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="co"># Adjust generation parameters as needed to control output style</span></span>
<span id="cb10-7"><a href="#cb10-7"></a>output_sequences <span class="op">=</span> model.generate(</span>
<span id="cb10-8"><a href="#cb10-8"></a>    input_ids,</span>
<span id="cb10-9"><a href="#cb10-9"></a>    max_length<span class="op">=</span>input_ids.shape[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">30</span>, <span class="co"># Generate up to 30 new tokens</span></span>
<span id="cb10-10"><a href="#cb10-10"></a>    num_return_sequences<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb10-11"><a href="#cb10-11"></a>    no_repeat_ngram_size<span class="op">=</span><span class="dv">2</span>,             <span class="co"># To avoid immediate repetition</span></span>
<span id="cb10-12"><a href="#cb10-12"></a>    do_sample<span class="op">=</span><span class="va">True</span>,                     <span class="co"># Use sampling for more diverse output</span></span>
<span id="cb10-13"><a href="#cb10-13"></a>    top_k<span class="op">=</span><span class="dv">50</span>,                           <span class="co"># Consider top 50 tokens</span></span>
<span id="cb10-14"><a href="#cb10-14"></a>    top_p<span class="op">=</span><span class="fl">0.95</span>,                         <span class="co"># Nucleus sampling</span></span>
<span id="cb10-15"><a href="#cb10-15"></a>    temperature<span class="op">=</span><span class="fl">0.8</span>,                    <span class="co"># Controls randomness (slightly higher for more variation)</span></span>
<span id="cb10-16"><a href="#cb10-16"></a>    pad_token_id<span class="op">=</span>tokenizer.eos_token_id <span class="co"># Ensure generation stops at EOS token</span></span>
<span id="cb10-17"><a href="#cb10-17"></a>)</span>
<span id="cb10-18"><a href="#cb10-18"></a></span>
<span id="cb10-19"><a href="#cb10-19"></a>generated_text <span class="op">=</span> tokenizer.decode(output_sequences[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-20"><a href="#cb10-20"></a><span class="bu">print</span>(<span class="st">"--- Generated Text ---"</span>)</span>
<span id="cb10-21"><a href="#cb10-21"></a><span class="bu">print</span>(generated_text)</span>
<span id="cb10-22"><a href="#cb10-22"></a><span class="bu">print</span>(<span class="st">"----------------------"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb11-1"><a href="#cb11-1"></a>--- Generated Text ---</span>
<span id="cb11-2"><a href="#cb11-2"></a>Sentence: The Sky is clear, it's time to fly.</span>
<span id="cb11-3"><a href="#cb11-3"></a>Translation: If you've already been in the game and can't get to the cockpit and get in touch with me, I'm trying to contact you. If</span>
<span id="cb11-4"><a href="#cb11-4"></a>----------------------</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To know in details how <code>model.generate()</code> works and what each parameter means check this <a href="https://sushobhon.github.io/posts/2025-07-01-Your-Own-Next-Token-Generator/">blog</a>.</p>
<p>Specifying Padding tokens if no padding token is there. As padding is not build in for casual Language models like GPT we need to specify it. Models like BERT or T5 are designed to handel padding token natively.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="co"># Set padding token</span></span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="cf">if</span> tokenizer.pad_token <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb12-3"><a href="#cb12-3"></a>    tokenizer.pad_token <span class="op">=</span> tokenizer.eos_token</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="tokenizing" class="level2">
<h2 class="anchored" data-anchor-id="tokenizing">Tokenizing</h2>
<p>The model can’t process raw text directly, so we need to tokenize the data using its tokenizer.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a><span class="co"># Step 3: Preparing the dataset for training (Tokenization)</span></span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="kw">def</span> tokenize_function(examples):</span>
<span id="cb13-3"><a href="#cb13-3"></a>    <span class="co"># Tokenize the text, padding and truncation will be handled by the data collator</span></span>
<span id="cb13-4"><a href="#cb13-4"></a>    <span class="cf">return</span> tokenizer(examples[<span class="st">"text"</span>])</span>
<span id="cb13-5"><a href="#cb13-5"></a></span>
<span id="cb13-6"><a href="#cb13-6"></a><span class="co"># Applying tokenize_function and removing other collumns</span></span>
<span id="cb13-7"><a href="#cb13-7"></a>tokenized_datasets <span class="op">=</span> dataset.<span class="bu">map</span>(</span>
<span id="cb13-8"><a href="#cb13-8"></a>    tokenize_function,</span>
<span id="cb13-9"><a href="#cb13-9"></a>    batched<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-10"><a href="#cb13-10"></a>    remove_columns<span class="op">=</span>[<span class="st">"sentence"</span>, <span class="st">"translation"</span>, <span class="st">"translation_extra"</span>, <span class="st">"text"</span>]</span>
<span id="cb13-11"><a href="#cb13-11"></a>)</span>
<span id="cb13-12"><a href="#cb13-12"></a></span>
<span id="cb13-13"><a href="#cb13-13"></a><span class="co"># Dataset after tokenization</span></span>
<span id="cb13-14"><a href="#cb13-14"></a><span class="bu">print</span>(tokenized_datasets[<span class="st">'train'</span>][<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We need to convert the tokenized data for batches before feeding it into the model. We can do that using <code>DataCollatorForLanguageModeling()</code> function from <code>transformers</code> packages. Also we have kept <code>mlm</code> or Masked Language Model as <code>False</code> as we are predicting next word we do not need Masking.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a><span class="co"># Data collator for causal language modeling</span></span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="co"># This will handle padding and creating the labels (which are the input ids shifted)</span></span>
<span id="cb14-3"><a href="#cb14-3"></a>data_collator <span class="op">=</span> DataCollatorForLanguageModeling(tokenizer<span class="op">=</span>tokenizer, mlm<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="training-model" class="level2">
<h2 class="anchored" data-anchor-id="training-model">Training Model</h2>
<p>Creating Training Arguments and Trainer Object.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a><span class="co"># Step 4: Set up the training arguments</span></span>
<span id="cb15-2"><a href="#cb15-2"></a>output_dir <span class="op">=</span> <span class="st">"./yoda_finetuned_model"</span></span>
<span id="cb15-3"><a href="#cb15-3"></a>training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb15-4"><a href="#cb15-4"></a>    output_dir<span class="op">=</span>output_dir,              <span class="co"># Location of Output Directory</span></span>
<span id="cb15-5"><a href="#cb15-5"></a>    overwrite_output_dir<span class="op">=</span><span class="va">True</span>,          <span class="co"># If directory already exists then overwrite</span></span>
<span id="cb15-6"><a href="#cb15-6"></a>    num_train_epochs<span class="op">=</span><span class="dv">5</span>,                 <span class="co"># Number of time the model will be trained on entire data</span></span>
<span id="cb15-7"><a href="#cb15-7"></a>    per_device_train_batch_size<span class="op">=</span><span class="dv">4</span>,      <span class="co"># Number of example will be trained at a time</span></span>
<span id="cb15-8"><a href="#cb15-8"></a>    per_device_eval_batch_size<span class="op">=</span><span class="dv">4</span>,       <span class="co"># Number of example will be evaluated at a time</span></span>
<span id="cb15-9"><a href="#cb15-9"></a>    eval_strategy<span class="op">=</span><span class="st">"epoch"</span>,              <span class="co"># Changed from evaluation_strategy</span></span>
<span id="cb15-10"><a href="#cb15-10"></a>    save_strategy<span class="op">=</span><span class="st">"epoch"</span>,              <span class="co"># Changed from save_strategy</span></span>
<span id="cb15-11"><a href="#cb15-11"></a>    logging_dir<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>output_dir<span class="sc">}</span><span class="ss">/logs"</span>,   <span class="co"># Loggs will be saved here</span></span>
<span id="cb15-12"><a href="#cb15-12"></a>    logging_steps<span class="op">=</span><span class="dv">50</span>,                   <span class="co"># Log saving frequently</span></span>
<span id="cb15-13"><a href="#cb15-13"></a>    learning_rate<span class="op">=</span><span class="fl">2e-5</span>,                 </span>
<span id="cb15-14"><a href="#cb15-14"></a>    weight_decay<span class="op">=</span><span class="fl">0.01</span>,</span>
<span id="cb15-15"><a href="#cb15-15"></a>    load_best_model_at_end<span class="op">=</span><span class="va">True</span>,        <span class="co"># Load the best model based on evaluation loss</span></span>
<span id="cb15-16"><a href="#cb15-16"></a>    metric_for_best_model<span class="op">=</span><span class="st">"eval_loss"</span>,</span>
<span id="cb15-17"><a href="#cb15-17"></a>)</span>
<span id="cb15-18"><a href="#cb15-18"></a></span>
<span id="cb15-19"><a href="#cb15-19"></a><span class="co"># Step 5: Initialize the Trainer</span></span>
<span id="cb15-20"><a href="#cb15-20"></a>trainer <span class="op">=</span> Trainer(</span>
<span id="cb15-21"><a href="#cb15-21"></a>    model<span class="op">=</span>model,</span>
<span id="cb15-22"><a href="#cb15-22"></a>    args<span class="op">=</span>training_args,</span>
<span id="cb15-23"><a href="#cb15-23"></a>    train_dataset<span class="op">=</span>tokenized_datasets[<span class="st">"train"</span>],</span>
<span id="cb15-24"><a href="#cb15-24"></a>    eval_dataset<span class="op">=</span>tokenized_datasets[<span class="st">"eval"</span>],</span>
<span id="cb15-25"><a href="#cb15-25"></a>    data_collator<span class="op">=</span>data_collator,</span>
<span id="cb15-26"><a href="#cb15-26"></a>)</span>
<span id="cb15-27"><a href="#cb15-27"></a></span>
<span id="cb15-28"><a href="#cb15-28"></a><span class="co"># Step 6: Start the training process</span></span>
<span id="cb15-29"><a href="#cb15-29"></a><span class="bu">print</span>(<span class="st">"Starting training..."</span>)</span>
<span id="cb15-30"><a href="#cb15-30"></a>trainer.train()</span>
<span id="cb15-31"><a href="#cb15-31"></a><span class="bu">print</span>(<span class="st">"Training finished."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb16"><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb16-1"><a href="#cb16-1"></a>Starting training...</span>
<span id="cb16-2"><a href="#cb16-2"></a>`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.</span>
<span id="cb16-3"><a href="#cb16-3"></a> [810/810 02:00, Epoch 5/5]</span>
<span id="cb16-4"><a href="#cb16-4"></a>Epoch   Training Loss   Validation Loss</span>
<span id="cb16-5"><a href="#cb16-5"></a>1   2.136600    1.926351</span>
<span id="cb16-6"><a href="#cb16-6"></a>2   1.866500    1.851621</span>
<span id="cb16-7"><a href="#cb16-7"></a>3   1.698700    1.839700</span>
<span id="cb16-8"><a href="#cb16-8"></a>4   1.616700    1.838783</span>
<span id="cb16-9"><a href="#cb16-9"></a>5   1.600100    1.836944</span>
<span id="cb16-10"><a href="#cb16-10"></a>There were missing keys in the checkpoint model loaded: ['lm_head.weight'].</span>
<span id="cb16-11"><a href="#cb16-11"></a>Training finished.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Loss Decreased from <code>2.13</code> to <code>1.6</code>.</p>
</section>
<section id="evaluating-the-model" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-the-model">Evaluating The Model</h2>
<p>Evaluating the model on Evaluation dataset</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a><span class="co"># Step 7: Evaluate the fine-tuned model</span></span>
<span id="cb17-2"><a href="#cb17-2"></a><span class="bu">print</span>(<span class="st">"Evaluating model..."</span>)</span>
<span id="cb17-3"><a href="#cb17-3"></a>eval_results <span class="op">=</span> trainer.evaluate(eval_dataset<span class="op">=</span>tokenized_datasets[<span class="st">"eval"</span>]) <span class="co"># Explicitly pass eval_dataset</span></span>
<span id="cb17-4"><a href="#cb17-4"></a><span class="bu">print</span>(<span class="ss">f"Evaluation results: </span><span class="sc">{</span>eval_results<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-5"><a href="#cb17-5"></a><span class="cf">if</span> <span class="st">'eval_loss'</span> <span class="kw">in</span> eval_results:</span>
<span id="cb17-6"><a href="#cb17-6"></a>    perplexity <span class="op">=</span> math.exp(eval_results[<span class="st">"eval_loss"</span>])</span>
<span id="cb17-7"><a href="#cb17-7"></a>    <span class="bu">print</span>(<span class="ss">f"Perplexity: </span><span class="sc">{</span>perplexity<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb18"><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb18-1"><a href="#cb18-1"></a>Evaluating model...</span>
<span id="cb18-2"><a href="#cb18-2"></a>Evaluation results: {'eval_loss': 1.8369437456130981, 'eval_runtime': 0.6711, 'eval_samples_per_second': 107.291, 'eval_steps_per_second': 26.823, 'epoch': 5.0}</span>
<span id="cb18-3"><a href="#cb18-3"></a>Perplexity: 6.277323815417289</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="testing" class="level2">
<h2 class="anchored" data-anchor-id="testing">Testing</h2>
<p>Let us test with actual english sentence…</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a><span class="co"># Example of generating text with the fine-tuned model</span></span>
<span id="cb19-2"><a href="#cb19-2"></a><span class="bu">print</span>(<span class="st">"Generating example text..."</span>)</span>
<span id="cb19-3"><a href="#cb19-3"></a>model.<span class="bu">eval</span>() <span class="co"># Set model to evaluation mode. This is a standard practice in pytorch. Here certain layers of the model freezes</span></span>
<span id="cb19-4"><a href="#cb19-4"></a></span>
<span id="cb19-5"><a href="#cb19-5"></a><span class="co"># Testing for given sentence</span></span>
<span id="cb19-6"><a href="#cb19-6"></a>prompt <span class="op">=</span> <span class="st">"Sentence: The Sky is clear, it's time to fly.</span><span class="ch">\n</span><span class="st">Translation:"</span> <span class="co"># Include the start of the target sequence</span></span>
<span id="cb19-7"><a href="#cb19-7"></a>input_ids <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">"pt"</span>).input_ids.to(model.device)</span>
<span id="cb19-8"><a href="#cb19-8"></a></span>
<span id="cb19-9"><a href="#cb19-9"></a><span class="co"># Generate text</span></span>
<span id="cb19-10"><a href="#cb19-10"></a><span class="co"># Adjust generation parameters as needed to control output style</span></span>
<span id="cb19-11"><a href="#cb19-11"></a>output_sequences <span class="op">=</span> model.generate(</span>
<span id="cb19-12"><a href="#cb19-12"></a>    input_ids,</span>
<span id="cb19-13"><a href="#cb19-13"></a>    max_length<span class="op">=</span>input_ids.shape[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">30</span>, <span class="co"># Generate up to 30 new tokens</span></span>
<span id="cb19-14"><a href="#cb19-14"></a>    num_return_sequences<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb19-15"><a href="#cb19-15"></a>    no_repeat_ngram_size<span class="op">=</span><span class="dv">2</span>,             <span class="co"># To avoid immediate repetition</span></span>
<span id="cb19-16"><a href="#cb19-16"></a>    do_sample<span class="op">=</span><span class="va">True</span>,                     <span class="co"># Use sampling for more diverse output</span></span>
<span id="cb19-17"><a href="#cb19-17"></a>    top_k<span class="op">=</span><span class="dv">50</span>,                           <span class="co"># Consider top 50 tokens</span></span>
<span id="cb19-18"><a href="#cb19-18"></a>    top_p<span class="op">=</span><span class="fl">0.95</span>,                         <span class="co"># Nucleus sampling</span></span>
<span id="cb19-19"><a href="#cb19-19"></a>    temperature<span class="op">=</span><span class="fl">0.8</span>,                    <span class="co"># Controls randomness (slightly higher for more variation)</span></span>
<span id="cb19-20"><a href="#cb19-20"></a>    pad_token_id<span class="op">=</span>tokenizer.eos_token_id <span class="co"># Ensure generation stops at EOS token</span></span>
<span id="cb19-21"><a href="#cb19-21"></a>)</span>
<span id="cb19-22"><a href="#cb19-22"></a></span>
<span id="cb19-23"><a href="#cb19-23"></a>generated_text <span class="op">=</span> tokenizer.decode(output_sequences[<span class="dv">0</span>], skip_special_tokens<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-24"><a href="#cb19-24"></a><span class="bu">print</span>(<span class="st">"--- Generated Text ---"</span>)</span>
<span id="cb19-25"><a href="#cb19-25"></a><span class="bu">print</span>(generated_text)</span>
<span id="cb19-26"><a href="#cb19-26"></a><span class="bu">print</span>(<span class="st">"----------------------"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode numberSource text number-lines code-with-copy"><code class="sourceCode"><span id="cb20-1"><a href="#cb20-1"></a>The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's attention_mask to obtain reliable results.</span>
<span id="cb20-2"><a href="#cb20-2"></a>Generating example text...</span>
<span id="cb20-3"><a href="#cb20-3"></a>--- Generated Text ---</span>
<span id="cb20-4"><a href="#cb20-4"></a>Sentence: The Sky is clear, it's time to fly.</span>
<span id="cb20-5"><a href="#cb20-5"></a>Translation: To fly, the Sky must. Yes, hrrmmm. Yrsssss. Time to soar, we must, and there is. H</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Pretty Good!! The model is able to translate.</p>
</section>
<section id="pros" class="level2">
<h2 class="anchored" data-anchor-id="pros">Pros</h2>
<ol type="1">
<li><strong>Maximum performance</strong> – Tailors the entire model to your specific dataset, often yielding the best results.</li>
<li><strong>Full control</strong> – Allows deep customization across all layers of the model.</li>
<li><strong>Better generalization on your domain</strong> – Learns complex patterns specific to your task or domain.</li>
<li><strong>No dependence on base model behavior</strong> – Overwrites pretrained knowledge if needed.</li>
<li><strong>Improved coherence and fluency</strong> – Especially in specialized tasks like translation, summarization, or domain-specific generation.</li>
</ol>
</section>
<section id="cons" class="level2">
<h2 class="anchored" data-anchor-id="cons">Cons</h2>
<ol type="1">
<li><strong>High computational cost</strong> – Requires significant GPU resources and memory.</li>
<li><strong>Longer training time</strong> – Full tuning can take hours or days, depending on model size and dataset.</li>
<li><strong>Risk of overfitting</strong> – Especially if the dataset is small or not diverse.</li>
<li><strong>Loses some general-purpose capabilities</strong> – The model may forget or override its broad pretrained knowledge.</li>
<li><strong>Storage-heavy</strong> – The fine-tuned model needs to store all updated parameters, increasing disk space usage.</li>
</ol>
</section>
<section id="alternatives" class="level2">
<h2 class="anchored" data-anchor-id="alternatives">Alternatives</h2>
<p>To avoid this cost intesive tunning there are other tunning methods. Take a detailed look -</p>
<ol type="1">
<li><strong>Prompt Tuning</strong></li>
<li><strong>Prefix Tuning</strong></li>
<li><strong>LoRA (Low-Rank Adaptation) or Q-LORA</strong></li>
<li><strong>Adapters</strong></li>
<li><strong>Instruction Tuning</strong></li>
<li><strong>Retrieval-Augmented Generation (RAG)</strong></li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/sushobhon\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>